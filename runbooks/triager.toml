# Triager Runbook
#
# Failure analysis and decision rules.
# Monitors for patterns of failures and triggers appropriate responses.

# ------------------------------------------------------------------------------
# Meta
# ------------------------------------------------------------------------------

[meta]
name = "triager"
description = "Failure analysis and decision rules"

# ------------------------------------------------------------------------------
# Actions
# ------------------------------------------------------------------------------

[action.notify-team]
cooldown = "15m"
command = "notify"
args = { level = "warning", message = "Multiple consecutive build failures" }

[action.pause-pipelines]
cooldown = "1h"
command = "disable_cron"
args = { pattern = "auto-*" }

[action.retry-with-isolation]
cooldown = "5m"
command = "retry_task"
args = { isolation = true }

[action.mark-flaky]
cooldown = "1h"
command = "tag_test"
args = { tag = "flaky" }

[action.analyze-failure]
cooldown = "30m"
command = "claude"
args = { prompt = "Analyze the recent failure and suggest root causes" }

[action.create-issue]
cooldown = "1h"
command = "create_issue"
args = { title = "Recurring failure detected", labels = "bug,triage" }

# ------------------------------------------------------------------------------
# Watchers
# ------------------------------------------------------------------------------

[watcher.build-failures]
source = { type = "events", pattern = "pipeline:failed:*" }
condition = { type = "consecutive_failures", count = 3 }
check_interval = "30s"

[[watcher.build-failures.response]]
action = "notify-team"

[[watcher.build-failures.response]]
action = "pause-pipelines"
delay = "5m"
requires_previous_failure = true

[watcher.test-flakiness]
source = { type = "events", pattern = "task:failed:test:*" }
condition = { type = "matches", pattern = "flaky|timeout|intermittent" }
check_interval = "1m"

[[watcher.test-flakiness.response]]
action = "retry-with-isolation"

[[watcher.test-flakiness.response]]
action = "mark-flaky"
delay = "30s"
requires_previous_failure = true

[watcher.merge-conflicts]
source = { type = "events", pattern = "strategy:merge:conflict:*" }
condition = { type = "consecutive_failures", count = 2 }
check_interval = "1m"

[[watcher.merge-conflicts.response]]
action = "notify-team"
args = { message = "Multiple merge conflicts - may need attention" }

[[watcher.merge-conflicts.response]]
action = "analyze-failure"
delay = "2m"
requires_previous_failure = true

[watcher.resource-exhaustion]
source = { type = "events", pattern = "semaphore:full:*" }
condition = { type = "exceeds", count = 10 }
check_interval = "5m"

[[watcher.resource-exhaustion.response]]
action = "notify-team"
args = { message = "Semaphore contention detected - consider scaling" }

# ------------------------------------------------------------------------------
# Crons (scheduled analysis tasks)
# ------------------------------------------------------------------------------

[cron.daily-health-check]
interval = "24h"
enabled = true
run = """
oj stats --json | jq '.failures_last_24h > 5' && oj action trigger notify-team
"""

[cron.weekly-cleanup-report]
interval = "168h"  # 7 days
enabled = true
run = """
oj scanner stats --json > /tmp/cleanup-report.json
oj notify --level info --message "Weekly cleanup: $(cat /tmp/cleanup-report.json | jq '.total_cleaned') resources cleaned"
"""
